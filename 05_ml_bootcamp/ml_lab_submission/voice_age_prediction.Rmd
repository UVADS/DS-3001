---
title: "ml_bootcamp"
author: "Adriel Kim"
date: "9/29/2020"
output:
  html_document:
    toc: TRUE
    theme: journal
    toc_float: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(tidyverse)
library(psych)
library(mltools)
library(data.table)
library(caret)
```
[caret documentation](http://topepo.github.io/caret/index.html)


## Phase I
[voice_Data_Dictionary](https://data.world/uci/voice)

```{r}
#Working to developed a model than can predict the gender of a person based on their voice

# Inference versus Prediction 

# Independent Business Metric - Assuming that knowledge of the gender of a person can be used to improve client experience, can we determine the gender of a person based on their voice measurements?

```
## Phase II 

### Scale/Center/Normalizing

```{r}
voice <- read_csv("voice.csv")
View(voice)
attach(voice)
describe(voice)
?scale
str(voice)

normalize <- function(x){
 (x - min(x)) / (max(x) - min(x))
}



(column_index <- tibble(colnames(voice)))


column_index

#label is a categorical attribute
voice$label[voice$label == "female"] <- 0
voice$label[voice$label == "male"] <- 1
voice[,"label"] <- lapply(voice[,"label"], as.factor)

str(voice)

#Now we can move forward in normalizing the numeric values, create a index based on numeric columns: 

abc <- names(select_if(voice, is.numeric))# select function to find the numeric variables 

#Use lapply to normalize the numeric values 

voice[abc] <- as_tibble(lapply(voice[abc], normalize))


str(voice)

```

### One-hot Encoding (Not necessary)

### Baseline/Prevalance 

```{r}
#no need for adding labels, since target is already binary
(prevalence <- table(voice$label)[[2]]/length(voice$label))
```
### Initial Model Building: Decision Tree Style  

```{r}
# Training, Evaluation, Tune, Evaluation, Test, Evaluation
# Divide up our data into three parts, Training, Tuning, and Test

#There is not a easy way to create 3 partitions using the createDataPartitions

#so we are going to use it twice. Mostly because we want to stratify on the variable we are working to predict. What does that mean?  

#clean up our dataset a bit by dropping the original ranking variable and the voice name which we can't really use. 

voice_dt <- voice#voice[,c("Rings")]
view(voice_dt)



part_index_1 <- caret::createDataPartition(voice_dt$label,
                                           times=1,
                                           p = 0.70,
                                           groups=1,
                                           list=FALSE)
View(part_index_1)
dim(voice_dt)

train <- voice_dt[part_index_1,]
tune_and_test <- voice_dt[-part_index_1, ]

#The we need to use the function again to create the tuning set 

tune_and_test_index <- createDataPartition(tune_and_test$label,
                                           p = .5,
                                           list = FALSE,
                                           times = 1)

tune <- tune_and_test[tune_and_test_index, ]
test <- tune_and_test[-tune_and_test_index, ]


dim(train)
dim(tune)
dim(test)

```

#### Using Caret package to fit a C5.0 version of a decision tree
Setting up the cross validation
[Caret_Documentation](http://topepo.github.io/caret/train-models-by-tag.html#Tree_Based_Model)
```{r}
#Cross validation process 

fitControl <- trainControl(method = "repeatedcv",
                          number = 10,
                          repeats = 5, 
                          returnResamp="all") 

# number - number of folds
# repeats - number of times the CV is repeated, here it's 5 take the average of
# those 5 repeats


# Choose the features and classes

```
#### Training and Evaluation 

```{r}
colnames(train)
features <- train[,c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)]
view(features)
target <- train[,"label"]


str(target)

set.seed(1984)
voice_mdl <- train(x=features,
                y=target$label,
                trControl=fitControl,
                method="C5.0",
                verbose=TRUE)

voice_mdl

```
Tune and Evaluation 
```{r}
voice_predict = predict(voice_mdl,tune,type= "raw")

confusionMatrix(as.factor(voice_predict), 
                as.factor(tune$label), 
                dnn=c("Prediction", "Actual"), 
                mode = "sens_spec")

varImp(voice_mdl)

plot(voice_mdl)


grid <- expand.grid(.winnow = c(TRUE,FALSE), 
                    .trials=c(20,30,40), 
                    .model=c("tree","rules"))
set.seed(1984)
voice_mdl_tune <- train(x=features,
                y=target$label,
                tuneGrid=grid,
                trControl=fitControl,
                method="C5.0",
                verbose=TRUE)

voice_mdl_tune
voice_mdl

plot(voice_mdl_tune)

# Want to evaluation again with the tune data using the new model 

voice_predict_tune = predict(voice_mdl_tune,tune,type= "raw")

confusionMatrix(as.factor(voice_predict_tune), 
                as.factor(tune$label), 
                dnn=c("Prediction", "Actual"), 
                mode = "sens_spec")


```

Test 

```{r}
view(test)
view(tune)
voice_predict_test = predict(voice_mdl_tune,test,type= "raw")

confusionMatrix(as.factor(voice_predict_test), 
                as.factor(test$label), 
                dnn=c("Prediction", "Actual"), 
                mode = "sens_spec")

```


