---
title: "KNN_lab_2"
author: "Brian Wright"
date: "8/17/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(mice)
```

Instructions:
Let's build a kNN model using the college completion data from last week. 

The data is messy and you have a degrees of freedom problem, as in, we have too many features.  

You've done most of the hard work already, so you should be ready to move forward with building your model. 

Use the question/target variable you submitted from last week and build a model to answer the question you created for this dataset. 
Build and optimize a kNN model to predict your target variable. Meaning use the tune set to select the correct k value. 

Experiment with the threshold function, what happens at higher and lower thresholds. Document what you see in comments. 

Evaluate the results using the confusion matrix (at the default threshold). Then talk through your question, summarize what concerns or positive elements do you have about the model? 

Example of how I cleaned the dataset
```{r}
url <- "https://query.data.world/s/yd5wiazzlj7aahmn4x37y7zq5pyh2h"

grad_data <- read_csv(url)

View(grad_data)# we can tell that a large number of the features will likely 
#need to be removed and we've got a rather large number of features/ 

# readme for the dataset - https://data.world/databeats/college-completion/workspace/file?filename=README.txt


#This will allow us to pull column numbers for sub-setting  
column_index <- tibble(colnames(grad_data))

x <- 40:56 #create a list so we don't have to type 16 numbers out

#Most of these columns have a good number of missing values or are not useful.  
grad_data_1 <- grad_data[ ,c(-28,-10,-11,-12,-x,-29,-37,-61,-57)]

#Make a new index
column_index <- tibble(colnames(grad_data_1))

#Looking better
View(grad_data_2)

#Dropped a bunch more that appeared to be repeats or not predictive 
grad_data_2 <- grad_data_1[ ,c(-1,-3,-4,-7,-9,-12,-13,-15,-16,-19,-22,-24,-30,-33,-34,-35,-36)]

#need to change the nulls to NAs 
grad_data_2[grad_data_2=="NULL"] <- NA

summary(grad_data_2)

#In looking at the hbcu (historically black colleges and universities, seems
# like the NAs should be 0s, let's change that back and convert to a factor)
grad_data_2$hbcu <- as.factor(ifelse(is.na(grad_data_2$hbcu),0,1))

#Ok better
table(grad_data_2$hbcu)
str(grad_data_2)

#convert several variables to factors 
x <- c("level","control")
grad_data_2[,x] <- lapply(grad_data_2[,x], as.factor)

#convert several variables to numbers 
x <- c("med_sat_value","grad_100_value","grad_100_percentile","grad_150_value","grad_150_percentile","retain_value","cohort_size","ft_fac_value")

grad_data_2[,x] <- lapply(grad_data_2[,x], as.numeric)

#Looking better
str(grad_data_2)
```

### Missing Data 
```{r}
#Now let's take a look at missing data issue
md.pattern(grad_data_2)

#let's drop med_stat_value then delete the rest of the NA columns 
grad_data_2 <- grad_data_2[,c(-1,-11)]
grad_data_3 <- grad_data_2[complete.cases(grad_data_2), ]

str(grad_data_3)#Ok looking good, still likely want to drop a few columns,need to normalize and one_hot encode before we move forward with model building.

str(grad_data)

md.pattern(grad_data_3)


```
