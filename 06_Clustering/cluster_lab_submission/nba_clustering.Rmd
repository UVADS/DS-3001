---
title: "Clustering Lab"
author: "Adriel Kim"
date: "10/19/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In a separate Rmarkdown document work through a similar process 
with the NBA data (nba2020-21 and nba_salaries_21), merge them together. 

You are a scout for the worst team in the NBA, probably the Wizards. Your 
general manager just heard about Data Science and thinks it can solve all the
teams problems!!! She wants you to figure out a way to find players that are 
high performing but maybe not highly paid that you can steal to get the team 
to the playoffs! 

Details: 

- Determine a way to use clustering to estimate based on performance if 
players are under or over paid, generally. 
- Then select three players you believe would be best for your team and explain why. 
- Provide a well commented and clean (knitted) report of your findings that can 
be presented to your GM. Include a rationale for variable selection, details 
on your approach and a overview of the results with supporting visualizations. 
 

Hints:

- Salary is the variable you are trying to understand 
- You can include numerous performance variables in the clustering but when 
interpreting you might want to use graphs that include variables that are the 
most correlated with Salary
- You'll need to standardize the variables before performing the clustering
- Be specific about why you selected the players that you did, more detail is 
better
- Use good coding practices, comment heavily, indent, don't use for loops unless
totally necessary and create modular sections that align with some outcome. If 
necessary create more than one script,list/load libraries at the top and don't 
include libraries that aren't used. 
```{r}

# Load libraries.
#library(e1071)
library(tidyverse)
library(plotly)
library(htmltools)
library(devtools)
library(caret)

```

### Load data and Preprocessing
Here, I merge NBA data, omit any rows with NA attributes, and rename columns.
```{r}
nba_salaries = read_csv("../data/nba_salaries_21.csv")
nba_stats = read_csv("../data/nba2020-21.csv")
nba_merged = merge(nba_salaries, nba_stats, by = "Player")
nba_processed = na.omit(nba_merged)#remove any rows with NA in them
names(nba_processed)[names(nba_processed) == "2020-21"] <- "Salary"



```
### Clustering variable selection
Here I select 5 different variables which I believe are correlated with salary and skill level. FG% is percentage of field goals, eFG% is similar with more weight toward 3-pointers, TRB is total number of rbounds, PTS is points, and BLK is number of blocks. These variables, when maximized are good indicators of a players skill level. I assume here that a player's skill level is directly related to a player's salary.

```{r}
plot(nba_processed$PTS, nba_processed$Salary, main="PTS vs Salary",
   xlab="PTS", ylab="Salary", pch=19)
plot(nba_processed$"FG%", nba_processed$Salary, main="FG% vs Salary",
   xlab="FG%", ylab="Salary", pch=19)
plot(nba_processed$"eFG%", nba_processed$Salary, main="eFG% vs Salary",
   xlab="eFG%", ylab="Salary", pch=19)
plot(nba_processed$TRB, nba_processed$Salary, main="TRB vs Salary",
   xlab="TRB", ylab="Salary", pch=19)
plot(nba_processed$BLK, nba_processed$Salary, main="BLK vs Salary",
   xlab="BLK", ylab="Salary", pch=19)
```
```{r}
nba_cluster_vars = scale(nba_processed[, c("FG%", "eFG%","TRB", "PTS", "BLK")])


```

### KMeans Clustering
I create two clusters using the Lloyd clustering algorithm.
```{r}
set.seed(42)
#cluster based on pay?
kmeans_obj_nba = kmeans(nba_cluster_vars, centers = 2, algorithm = "Lloyd")

kmeans_obj_nba

# View the results of each output of the kmeans function.
head(kmeans_obj_nba)

```

### Visualizations
```{r}
#Visualize the output
clusters_nba = as.factor(kmeans_obj_nba$cluster)


ggplot(nba_processed, aes(x = TRB, 
                            y = PTS,
                            shape = clusters_nba)) + 
  geom_point(size = 6) +
  ggtitle("PTS vs. FG% of NBA Players in 2020-21") +
  xlab("TRB (Total Rebounds)") +
  ylab("PTS (Points)") +
  scale_shape_manual(name = "Cluster", 
                     labels = c("Cluster 1", "Cluster 2"),
                     values = c("1", "2")) +
  theme_light()
```

```{r}
player_label_usable=str_replace_all(nba_processed$Player,"[^[:graph:]]", " ") 

ggplot(nba_processed, aes(  label=player_label_usable,
                            x = TRB, 
                            y = PTS,
                            color = Salary,  #<- tell R how to color 
                            #   the data points
                            shape = clusters_nba)) + 
  geom_point(size = 2) +
  geom_text(size=2, hjust= -0.1, nudge_x=0.1)+
  ggtitle("TRB vs. PTS of NBA Players in 2020-21") +
  xlab("TRB (Total Rebounds)") +
  ylab("PTS (Points)") +
  scale_shape_manual(name = "Cluster",
                     labels = c("Cluster 1", "Cluster 2"),
                     values = c("1", "2")) +
  scale_color_gradient(low="blue", high="red")

  theme_light()
```
### Clustering Evauation
```{r}
#Evaluate the quality of the clustering 
# Inter-cluster variance,
num_nba = kmeans_obj_nba$betweenss

# Total variance, "totss" is the sum of the distances
# between all the points in the data set.
denom_nba = kmeans_obj_nba$totss

# Variance accounted for by clusters.
(var_exp_Rep = num_nba / denom_nba)

```

```{r}
#Use the function we created to evaluate several different number of clusters

# Run an algorithm with 3 centers.
set.seed(1)
kmeans_obj_nba3 = kmeans(nba_cluster_vars, centers = 3, algorithm = "Lloyd")

# Inter-cluster variance.
num_nba3 = kmeans_obj_nba3$betweenss

# Total variance.
denom_nba3 = kmeans_obj_nba3$totss

# Variance accounted for by clusters.
(var_exp_nba3 = num_nba3 / denom_nba3)

total.var = var(nba_cluster_vars[,c("FG%")])+var(nba_cluster_vars[,c("eFG%")])+var(nba_cluster_vars[,c("TRB")])+var(nba_cluster_vars[,c("PTS")])+var(nba_cluster_vars[,c("BLK")])

total.var.km = (kmeans_obj_nba$betweenss+kmeans_obj_nba$tot.withinss)/(nrow(nba_cluster_vars)-1) 

total.var
total.var.km
```
### Elbow Plot to Determine Best K
```{r}
# The function explained_variance wraps our code for calculating 
# the variance explained by clustering.
explained_variance = function(data_in, k){
  
  # Running the kmeans algorithm.
  set.seed(1)
  kmeans_obj = kmeans(data_in, centers = k, algorithm = "Lloyd", iter.max = 30)
  
  # Variance accounted for by clusters:
  # var_exp = intercluster variance / total variance
  var_exp = kmeans_obj$betweenss / kmeans_obj$totss
  var_exp  
}
```


```{r}
#Create a elbow chart of the output
# Recall the variable we are using for the data that we're clustering.
View(nba_cluster_vars)

# The sapply() function plugs in several values into our explained_variance function.
#sapply() takes a vector, lapply() takes a dataframe
explained_var_nba = sapply(1:10, explained_variance, data_in = nba_cluster_vars)

View(explained_var_nba)


# Data for ggplot2.
elbow_data_nba = data.frame(k = 1:10, explained_var_nba)
View(elbow_data_nba)

# Plotting data.
ggplot(elbow_data_nba, 
       aes(x = k,  
           y = explained_var_nba)) + 
  geom_point(size = 4) +           #<- sets the size of the data points
  geom_line(size = 1) +            #<- sets the thickness of the line
  xlab('k') + 
  ylab('Inter-cluster Variance / Total Variance') + 
  theme_light()
```

It seems here that the best K is between 2 and 5.

### Conclusion
My top three players would be Luka Doncic, Zion Williamson, and Donavan Mitchel. All three players exhibit high 
levels of skill in the visualization above. Both have a high number of points and total rebounds, which are strong
indicators of their skill level. However, they seem underpaid compared to other players within their same cluster. Their salaries
are indicated by the label color, which is closer to blue. They would be good candidates to select for our team which requires 
highly skilled but less expensive players. 














